device: &device cuda
image_size: &image_size 112
batch_size: &batch_size 32
learning_rate: &lr 0.1
accumulate_grad_batches: &accumulate_grad_batches 2
checkpoint: &resume
fast_dev_run: &fast_test 0
overfit_batches: &overfit 0

model:
  device: *device
  batch_size: *batch_size
  learning_rate: *lr
  image_size: *image_size
  checkpoint: *resume
  trial_path: /home/omnisky/yjc/PLIntegration/data/union_test_trial.txt

  train_ds:
    __target__:
      - PLIntegration.datasets.video.MotionDataset
    args:
      - base_dir: &path /data/YouTubeFaces/frames
        manifest_filepath: *path
        loader:
          batch_size: *batch_size
          num_workers: 8
          pin_memory: True
          shuffle: True
          drop_last: False
        transformers:
          __target__:
            - torchvision.transforms.Resize
            - torchvision.transforms.ToTensor
          args:
            - size:
              - *image_size
              - *image_size
            - null

  validation_ds:
    __target__:
      - PLIntegration.datasets.video.TrialTestOld
    args:
      - base_dir: /data/REID/frames
        is_train: false
        loader:
          batch_size: *batch_size
          num_workers: 8
          pin_memory: True
          shuffle: False
          drop_last: False

        transformers:
          __target__:
            - torchvision.transforms.Resize
            - torchvision.transforms.ToTensor
          args:
            - size:
              - *image_size
              - *image_size
            - null

  test_ds:
    __target__:
      - PLIntegration.datasets.video.TrialTestOld
    args:
      - base_dir: /data/REID/frames
        is_train: false
        loader:
          batch_size: *batch_size
          num_workers: 8
          pin_memory: True
          shuffle: False
          drop_last: False

        transformers:
          __target__:
            - torchvision.transforms.Resize
            - torchvision.transforms.ToTensor
          args:
            - size:
              - *image_size
              - *image_size
            - null

  feature_extractor:
    __target__: PLIntegration.networks._3d.resnet.resnext3d101
    input_channels: 3
    shortcut_type: B
    cardinality: 32
    conv1_t_size: 7
    conv1_t_stride: 1
    device: *device
    STDA_input_shape:
      - 1024
      - 2
      - 7
      - 7
    #    layers: &id002
    #      - 3
    #      - 4
    #      - 36
    #      - 3
    dropout: 0

  embedding_aggregator:
    __target__: PLIntegration.networks.aggregators.pooling.AdaAvgPool
    pool_dims: 3
    output_size:
      - 1
      - 1
      - 1
    linear: false
    in_features: 2048
    embed_size: &embed_size 2048

  loss_function:
    __target__: PLIntegration.networks.loss.ce.ram_softmax.MVRealAMSoftmax
    scale: 64
    margin: 0.35
    t: 0.2
    fixed: false
    gamma: 2.0
    lmbd: 0.2
    easy_margin: false
    embed_size: *embed_size
    num_classes: 1595

  optimizer:
    __target__: torch.optim.SGD
    args:
      lr: *lr
      weight_decay: 0.0001
      momentum: 0.9

    lr_scheduler:
      __target__: torch.optim.lr_scheduler.MultiStepLR
      interval: step # step or epoch
      args:
        milestones:
          - 10e3
          - 20e3
          - 30e3
        gamma: 0.1
        last_epoch: null # computed at runtime or explicitly set here

trainer:
  gpus: 1 # number of gpus
  max_epochs: null
  max_steps: 40e3 # computed at runtime if not set
  accumulate_grad_batches: *accumulate_grad_batches
  precision: 32
  deterministic: False
  benchmark: True
  enable_checkpointing: True
  profiler: "simple"
  detect_anomaly: True
  resume_from_checkpoint: *resume
  log_every_n_steps: 100  # Interval of logging.
  val_check_interval: 1.0
  check_val_every_n_epoch: 20
  num_sanity_val_steps: -1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  track_grad_norm: -1
  fast_dev_run: *fast_test
  overfit_batches: *overfit

callbacks:
  __target__:
    - pytorch_lightning.callbacks.RichModelSummary
    - PLIntegration.utils.progressbar.CustomProgressBar
    - pytorch_lightning.callbacks.LearningRateMonitor
    - pytorch_lightning.callbacks.ModelCheckpoint

  args:
    - max_depth: 2
    - refresh_rate: 1
      position: 0
    - null
    - dirpath: "checkpoints"
      filename: "{epoch}-{train_loss:.2f}-{EER:.2f}"
      monitor: EER
      verbose: True
      save_top_k: 3
      save_last: True
      mode: min
      auto_insert_metric_name: True
      every_n_epochs: null

loggers:
  __target__:
    - pytorch_lightning.loggers.TensorBoardLogger

  args:
    - save_dir: "tb_logs"
      name: ""
      version: ""
      log_graph: True
      default_hp_metric: True
      prefix: ""
      sub_dir: None


